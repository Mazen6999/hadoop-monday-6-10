{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "621ac4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-4.0.1.tar.gz (434.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.2/434.2 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.9 (from pyspark)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-4.0.1-py2.py3-none-any.whl size=434813860 sha256=728bed2ecd81d98cca24c35f1ecf9aeca4e95ba262398358175feb7cb580b436\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/31/9f/68/f89fb34ccd886909be7d0e390eaaf97f21efdf540c0ee8dbcd\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pyspark]m1/2\u001b[0m [pyspark]\n",
      "\u001b[1A\u001b[2KSuccessfully installed py4j-0.10.9.9 pyspark-4.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b48d3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d446bc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb77c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/10/06 18:06:01 WARN Utils: Your hostname, codespaces-c6c251, resolves to a loopback address: 127.0.0.1; using 10.0.4.184 instead (on interface eth0)\n",
      "25/10/06 18:06:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/06 18:06:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    ".appName('Test') \\\n",
    ".master('local[*]') \\\n",
    ".config('spark.driver.memory','2g') \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f9d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Mazen',25),('Omar',22)]\n",
    "columns = ['name','age']\n",
    "df = spark.createDataFrame(data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05dd384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b4df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('age', IntegerType(), True),\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "086055e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88d54f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+-----+\n",
      "|   name|age|grad_year|grade|\n",
      "+-------+---+---------+-----+\n",
      "|  Alice| 22|     2023|    A|\n",
      "|    Bob| 24|     2022|    B|\n",
      "|Charlie| 23|     2023|   A+|\n",
      "+-------+---+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('age', IntegerType(), True),\n",
    "    StructField('grad_year', IntegerType(), True),\n",
    "    StructField('grade', StringType(), True)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (\"Alice\", 22, 2023, \"A\"),\n",
    "    (\"Bob\", 24, 2022, \"B\"),\n",
    "    (\"Charlie\", 23, 2023, \"A+\")\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99bee427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+-----+-------+\n",
      "|   name|age|grad_year|grade|country|\n",
      "+-------+---+---------+-----+-------+\n",
      "|  Alice| 22|     2023|    A|  egypt|\n",
      "|    Bob| 24|     2022|    B|  egypt|\n",
      "|Charlie| 23|     2023|   A+|  egypt|\n",
      "+-------+---+---------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df_modified = df.withColumn('country', lit('egypt')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ceed89bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      " |-- mass: double (nullable = true)\n",
      " |-- radius: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('celestial_data.csv',header=True,inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6894e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------------+--------+--------+------+\n",
      "| id|    name|        type|distance|    mass|radius|\n",
      "+---+--------+------------+--------+--------+------+\n",
      "|  1|     Sun|        Star|     0.0|1.989E30|695700|\n",
      "|  2|   Earth|      Planet|     1.0|5.972E24|  6371|\n",
      "|  3|    Moon|        Moon| 0.00257| 7.35E22|  1737|\n",
      "|  4|    Mars|      Planet|   1.524|6.417E23|  3389|\n",
      "|  5| Jupiter|      Planet|     5.2|1.898E27| 69911|\n",
      "|  6|  Saturn|      Planet|     9.5|5.683E26| 58232|\n",
      "|  7|  Uranus|      Planet|    19.8|8.681E25| 25362|\n",
      "|  8| Neptune|      Planet|    30.1|1.024E26| 24622|\n",
      "|  9|   Pluto|Dwarf Planet|    39.5|1.309E22|  1188|\n",
      "| 10|    Eris|Dwarf Planet|    67.8| 1.66E22|  1163|\n",
      "| 11|  Haumea|Dwarf Planet|    43.1|4.006E21|   816|\n",
      "| 12|Makemake|Dwarf Planet|    45.8|  3.1E21|   715|\n",
      "| 13|   Ceres|    Asteroid|    2.77|9.393E20|   473|\n",
      "| 14|   Vesta|    Asteroid|    2.36| 2.59E20|   262|\n",
      "| 15|  Pallas|    Asteroid|    2.77| 2.11E20|   272|\n",
      "| 16|  Hygiea|    Asteroid|    3.14| 8.32E19|   215|\n",
      "| 17|      Io|        Moon|     5.2| 8.93E22|  1821|\n",
      "| 18|  Europa|        Moon|     5.2|  4.8E22|  1560|\n",
      "| 19|Ganymede|        Moon|     5.2| 1.48E23|  2634|\n",
      "| 20|Callisto|        Moon|     5.2| 1.08E23|  2410|\n",
      "+---+--------+------------+--------+--------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dccb166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+--------+--------+------+\n",
      "| id|   name|  type|distance|    mass|radius|\n",
      "+---+-------+------+--------+--------+------+\n",
      "|  2|  Earth|Planet|     1.0|5.972E24|  6371|\n",
      "|  4|   Mars|Planet|   1.524|6.417E23|  3389|\n",
      "|  5|Jupiter|Planet|     5.2|1.898E27| 69911|\n",
      "|  6| Saturn|Planet|     9.5|5.683E26| 58232|\n",
      "|  7| Uranus|Planet|    19.8|8.681E25| 25362|\n",
      "|  8|Neptune|Planet|    30.1|1.024E26| 24622|\n",
      "| 39|Mercury|Planet|    0.39|3.301E23|  2440|\n",
      "| 40|  Venus|Planet|    0.72|4.867E24|  6052|\n",
      "+---+-------+------+--------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "planets_df = df.filter(col(\"type\") == \"Planet\")\n",
    "planets_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7efe97b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|    name|\n",
      "+---+--------+\n",
      "|  1|     Sun|\n",
      "|  2|   Earth|\n",
      "|  3|    Moon|\n",
      "|  4|    Mars|\n",
      "|  5| Jupiter|\n",
      "|  6|  Saturn|\n",
      "|  7|  Uranus|\n",
      "|  8| Neptune|\n",
      "|  9|   Pluto|\n",
      "| 10|    Eris|\n",
      "| 11|  Haumea|\n",
      "| 12|Makemake|\n",
      "| 13|   Ceres|\n",
      "| 14|   Vesta|\n",
      "| 15|  Pallas|\n",
      "| 16|  Hygiea|\n",
      "| 17|      Io|\n",
      "| 18|  Europa|\n",
      "| 19|Ganymede|\n",
      "| 20|Callisto|\n",
      "+---+--------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.select('id','name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9deae5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  2|  Earth|\n",
      "|  4|   Mars|\n",
      "|  5|Jupiter|\n",
      "|  6| Saturn|\n",
      "|  7| Uranus|\n",
      "|  8|Neptune|\n",
      "| 39|Mercury|\n",
      "| 40|  Venus|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"type\") == \"Planet\").select('id','name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cac71e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------------+--------+--------+------+-----+\n",
      "| id|    name|        type|distance|    mass|radius| size|\n",
      "+---+--------+------------+--------+--------+------+-----+\n",
      "|  1|     Sun|        Star|     0.0|1.989E30|695700| huge|\n",
      "|  2|   Earth|      Planet|     1.0|5.972E24|  6371| huge|\n",
      "|  3|    Moon|        Moon| 0.00257| 7.35E22|  1737| huge|\n",
      "|  4|    Mars|      Planet|   1.524|6.417E23|  3389| huge|\n",
      "|  5| Jupiter|      Planet|     5.2|1.898E27| 69911| huge|\n",
      "|  6|  Saturn|      Planet|     9.5|5.683E26| 58232| huge|\n",
      "|  7|  Uranus|      Planet|    19.8|8.681E25| 25362| huge|\n",
      "|  8| Neptune|      Planet|    30.1|1.024E26| 24622| huge|\n",
      "|  9|   Pluto|Dwarf Planet|    39.5|1.309E22|  1188| huge|\n",
      "| 10|    Eris|Dwarf Planet|    67.8| 1.66E22|  1163| huge|\n",
      "| 11|  Haumea|Dwarf Planet|    43.1|4.006E21|   816| huge|\n",
      "| 12|Makemake|Dwarf Planet|    45.8|  3.1E21|   715| huge|\n",
      "| 13|   Ceres|    Asteroid|    2.77|9.393E20|   473| huge|\n",
      "| 14|   Vesta|    Asteroid|    2.36| 2.59E20|   262|small|\n",
      "| 15|  Pallas|    Asteroid|    2.77| 2.11E20|   272|small|\n",
      "| 16|  Hygiea|    Asteroid|    3.14| 8.32E19|   215|small|\n",
      "| 17|      Io|        Moon|     5.2| 8.93E22|  1821| huge|\n",
      "| 18|  Europa|        Moon|     5.2|  4.8E22|  1560| huge|\n",
      "| 19|Ganymede|        Moon|     5.2| 1.48E23|  2634| huge|\n",
      "| 20|Callisto|        Moon|     5.2| 1.08E23|  2410| huge|\n",
      "+---+--------+------------+--------+--------+------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "#add col if mass > a number we write \"huge\" otherwise \"small\"\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"size\",\n",
    "    when(col(\"mass\") > 2.59E20, \"huge\").otherwise(\"small\")\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78a97b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+--------+----+------+----+\n",
      "| id|name|type|distance|mass|radius|size|\n",
      "+---+----+----+--------+----+------+----+\n",
      "+---+----+----+--------+----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create a condition for checking nulls in any column\n",
    "null_conditions = [col(c).isNull() for c in df.columns]\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "null_rows = df.filter(reduce(lambda x, y: x | y, null_conditions))\n",
    "null_rows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cb9ca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------------+--------+--------+------+-----+\n",
      "| id|    name|        type|distance|    mass|radius| size|\n",
      "+---+--------+------------+--------+--------+------+-----+\n",
      "|  1|     Sun|        Star|     0.0|1.989E30|695700| huge|\n",
      "|  2|   Earth|      Planet|     1.0|5.972E24|  6371| huge|\n",
      "|  3|    Moon|        Moon| 0.00257| 7.35E22|  1737| huge|\n",
      "|  4|    Mars|      Planet|   1.524|6.417E23|  3389| huge|\n",
      "|  5| Jupiter|      Planet|     5.2|1.898E27| 69911| huge|\n",
      "|  6|  Saturn|      Planet|     9.5|5.683E26| 58232| huge|\n",
      "|  7|  Uranus|      Planet|    19.8|8.681E25| 25362| huge|\n",
      "|  8| Neptune|      Planet|    30.1|1.024E26| 24622| huge|\n",
      "|  9|   Pluto|Dwarf Planet|    39.5|1.309E22|  1188| huge|\n",
      "| 10|    Eris|Dwarf Planet|    67.8| 1.66E22|  1163| huge|\n",
      "| 11|  Haumea|Dwarf Planet|    43.1|4.006E21|   816| huge|\n",
      "| 12|Makemake|Dwarf Planet|    45.8|  3.1E21|   715| huge|\n",
      "| 13|   Ceres|    Asteroid|    2.77|9.393E20|   473| huge|\n",
      "| 14|   Vesta|    Asteroid|    2.36| 2.59E20|   262|small|\n",
      "| 15|  Pallas|    Asteroid|    2.77| 2.11E20|   272|small|\n",
      "| 16|  Hygiea|    Asteroid|    3.14| 8.32E19|   215|small|\n",
      "| 17|      Io|        Moon|     5.2| 8.93E22|  1821| huge|\n",
      "| 18|  Europa|        Moon|     5.2|  4.8E22|  1560| huge|\n",
      "| 19|Ganymede|        Moon|     5.2| 1.48E23|  2634| huge|\n",
      "| 20|Callisto|        Moon|     5.2| 1.08E23|  2410| huge|\n",
      "+---+--------+------------+--------+--------+------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with any null values\n",
    "clean_df = df.na.drop()\n",
    "clean_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cd6e577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+--------+----+------+----+\n",
      "| id|name|type|distance|mass|radius|size|\n",
      "+---+----+----+--------+----+------+----+\n",
      "+---+----+----+--------+----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'mass' column is null\n",
    "null_mass_rows = df.filter(col(\"mass\").isNull())\n",
    "null_mass_rows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05d9b387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------+\n",
      "|   name|  type|    mass|\n",
      "+-------+------+--------+\n",
      "|  Earth|Planet|5.972E24|\n",
      "|   Mars|Planet|6.417E23|\n",
      "|Jupiter|Planet|1.898E27|\n",
      "| Saturn|Planet|5.683E26|\n",
      "| Uranus|Planet|8.681E25|\n",
      "|Neptune|Planet|1.024E26|\n",
      "|Mercury|Planet|3.301E23|\n",
      "|  Venus|Planet|4.867E24|\n",
      "+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"celestial_objects\")\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT name, type, mass \n",
    "    FROM celestial_objects \n",
    "    WHERE type = 'Planet'\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7664cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.mode('overwrite') \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('delimiter', ',') \\\n",
    "    .csv('output_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "979b6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
